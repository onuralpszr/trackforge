{"config":{"separator":"[\\s\\-_,:!=\\[\\]()\\\\\"`/]+|\\.(?!\\d)"},"items":[{"location":"","level":1,"title":"Index","text":"<p>Trackforge is a unified, high-performance computer vision tracking library built with Rust and exposed to Python. It implements state-of-the-art algorithms like ByteTrack with generic Kalman Filters.</p>","path":["Index"],"tags":[]},{"location":"#features","level":2,"title":"Features","text":"<ul> <li>üöÄ High Performance: Written in Rust for maximum speed and memory safety.</li> <li>üêç Python Bindings: Seamless integration with the Python ecosystem via PyO3.</li> <li>üëÅÔ∏è Computer Vision Ready: Designed for real-time tracking tasks.</li> <li>üõ†Ô∏è Unified API: Consistent interface for various tracking algorithms.</li> </ul>","path":["Index"],"tags":[]},{"location":"#quick-start","level":2,"title":"Quick Start","text":"","path":["Index"],"tags":[]},{"location":"#installation","level":3,"title":"Installation","text":"<pre><code>pip install trackforge\n</code></pre>","path":["Index"],"tags":[]},{"location":"#usage","level":3,"title":"Usage","text":"<pre><code>import trackforge\n\n# Example usage (update with actual API)\ntracker = trackforge.ByteTrack()\n</code></pre>","path":["Index"],"tags":[]},{"location":"#documentation","level":2,"title":"Documentation","text":"<ul> <li>Python API Reference</li> <li>Rust API Reference</li> </ul>","path":["Index"],"tags":[]},{"location":"examples/","level":1,"title":"Examples","text":"","path":["Examples"],"tags":[]},{"location":"examples/#rust-examples","level":2,"title":"Rust Examples","text":"","path":["Examples"],"tags":[]},{"location":"examples/#bytetrack-demo","level":3,"title":"ByteTrack Demo","text":"<pre><code>use trackforge::trackers::byte_track::ByteTrack;\n\nfn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {\n    // Initialize ByteTrack\n    // track_thresh = 0.5: Threshold for high confidence detections\n    // track_buffer = 30: Frames to keep lost tracks alive\n    // match_thresh = 0.8: IoU threshold for matching\n    // det_thresh = 0.6: Threshold for detection initialization\n    let mut tracker = ByteTrack::new(0.5, 30, 0.8, 0.6);\n\n    // Simulated detection input: [x, y, w, h], score, class_id\n    let frame_1_detections = vec![\n        ([100.0, 100.0, 50.0, 100.0], 0.9, 0),\n        ([200.0, 200.0, 60.0, 120.0], 0.85, 0),\n    ];\n\n    println!(\"Processing Frame 1...\");\n    let tracks_1 = tracker.update(frame_1_detections);\n\n    for t in tracks_1 {\n        println!(\n            \"Track ID: {}, Box: {:?}, Score: {:.2}\",\n            t.track_id, t.tlwh, t.score\n        );\n    }\n\n    // Simulated movement for Frame 2\n    let frame_2_detections = vec![\n        ([105.0, 102.0, 50.0, 100.0], 0.92, 0), // Moved slightly\n        ([202.0, 201.0, 60.0, 120.0], 0.88, 0),\n    ];\n\n    println!(\"\\nProcessing Frame 2...\");\n    let tracks_2 = tracker.update(frame_2_detections);\n\n    for t in tracks_2 {\n        println!(\n            \"Track ID: {}, Box: {:?}, Score: {:.2}\",\n            t.track_id, t.tlwh, t.score\n        );\n    }\n\n    Ok(())\n}\n</code></pre>","path":["Examples"],"tags":[]},{"location":"examples/#python-examples","level":2,"title":"Python Examples","text":"","path":["Examples"],"tags":[]},{"location":"examples/#bytetrack-demo_1","level":3,"title":"ByteTrack Demo","text":"<pre><code>import cv2\nfrom ultralytics import YOLO\nimport trackforge\nimport time\n\ndef run_tracking(video_path=\"test_video.mp4\", output_path=\"output_tracking.mp4\"):\n    # Load model\n    model = YOLO(\"yolo11n.pt\")\n\n    # Initialize Tracker\n    # track_thresh=0.1, track_buffer=30, match_thresh=0.8, det_thresh=0.1\n    tracker = trackforge.ByteTrack(0.1, 30, 0.8, 0.1)\n\n    # Open Video\n    cap = cv2.VideoCapture(video_path)\n    if not cap.isOpened():\n        print(f\"Error opening video file {video_path}\")\n        return\n\n    # Video Writer\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n\n    # Use MP4V codec\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\n    frame_count = 0\n    t0 = time.time()\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        frame_count += 1\n\n        # Run Detection\n        results = model.predict(frame, verbose=False)\n\n        # Prepare detections for Rust tracker\n        detections_for_tracker = []\n\n        for result in results:\n            boxes = result.boxes\n            for box in boxes:\n                # get tlwh\n                xyxy = box.xyxy[0].cpu().numpy()\n                x1, y1, x2, y2 = xyxy\n                w = x2 - x1\n                h = y2 - y1\n                tlwh = [float(x1), float(y1), float(w), float(h)]\n                conf = float(box.conf[0].cpu().numpy())\n                cls = int(box.cls[0].cpu().numpy())\n\n                detections_for_tracker.append((tlwh, conf, cls))\n\n        # Update Tracker\n        # Returns list of (track_id, tlwh, score, class_id)\n        online_tracks = tracker.update(detections_for_tracker)\n\n        # Draw Tracks\n        for t in online_tracks:\n            track_id = t[0]\n            tlwh = t[1]\n            score = t[2]\n            class_id = t[3]\n\n            x1, y1, w, h = tlwh\n            x2 = x1 + w\n            y2 = y1 + h\n\n            # Draw box\n            color = (0, 255, 0) # Green\n            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n\n            # Draw Label\n            label = f\"ID: {track_id} {model.names[class_id]} {score:.2f}\"\n            cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n\n        # Draw frame count\n        cv2.putText(frame, f\"Frame: {frame_count}\", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n\n        out.write(frame)\n        if frame_count % 50 == 0:\n            print(f\"Processed {frame_count} frames...\")\n\n    t1 = time.time()\n    print(f\"Done. Processed {frame_count} frames in {t1-t0:.2f}s ({(frame_count / (t1-t0)):.1f} fps)\")\n\n    cap.release()\n    out.release()\n    print(f\"Saved output video to {output_path}\")\n\nif __name__ == \"__main__\":\n    run_tracking()\n</code></pre>","path":["Examples"],"tags":[]},{"location":"api/","level":1,"title":"Crate <code>trackforge</code>","text":"<p>Version: 0.1.5</p> <p>Trackforge is a unified, high-performance computer vision tracking library, implemented in Rust and exposed as a Python package.</p> <p>It provides state-of-the-art tracking algorithms like ByteTrack, optimized for speed and ease of use in both Rust and Python environments.</p>","path":["Crate trackforge"],"tags":[]},{"location":"api/#features","level":2,"title":"Features","text":"<ul> <li>High Performance: Native Rust implementation for maximum speed and memory safety.</li> <li>Python Bindings: Seamless integration with the Python ecosystem using <code>pyo3</code>.</li> <li>Unified API: Consistent interface for tracking tasks across both languages.</li> <li>ByteTrack: Robust multi-object tracking using Kalman filters and IoU matching.</li> </ul>","path":["Crate trackforge"],"tags":[]},{"location":"api/#usage-rust","level":2,"title":"Usage (Rust)","text":"<pre><code>use trackforge::trackers::byte_track::ByteTrack;\n\n// Initialize ByteTrack\nlet mut tracker = ByteTrack::new(0.5, 30, 0.8, 0.6);\n\n// Detections: Vec&lt;([f32; 4], f32, i64)&gt;\nlet detections = vec![\n    ([100.0, 100.0, 50.0, 100.0], 0.9, 0),\n];\n\n// Update\nlet tracks = tracker.update(detections);\n\nfor t in tracks {\n    println!(\"ID: {}, Box: {:?}\", t.track_id, t.tlwh);\n}\n</code></pre>","path":["Crate trackforge"],"tags":[]},{"location":"api/#quick-reference","level":2,"title":"Quick Reference","text":"Item Kind Description <code>trackers</code> mod <code>traits</code> mod <code>types</code> mod <code>utils</code> mod","path":["Crate trackforge"],"tags":[]},{"location":"api/#modules","level":2,"title":"Modules","text":"<ul> <li><code>trackers</code></li> <li><code>traits</code></li> <li><code>types</code></li> <li><code>utils</code></li> </ul>","path":["Crate trackforge"],"tags":[]},{"location":"api/trackers/","level":1,"title":"Module trackers","text":"<p>trackforge / trackers</p>","path":["Module trackers"],"tags":[]},{"location":"api/trackers/#module-trackers","level":1,"title":"Module <code>trackers</code>","text":"","path":["Module trackers"],"tags":[]},{"location":"api/trackers/#quick-reference","level":2,"title":"Quick Reference","text":"Item Kind Description <code>byte_track</code> mod # ByteTrack <code>deepsort</code> mod","path":["Module trackers"],"tags":[]},{"location":"api/trackers/#modules","level":2,"title":"Modules","text":"<ul> <li><code>byte_track</code> ‚Äî # ByteTrack</li> <li><code>deepsort</code></li> </ul>","path":["Module trackers"],"tags":[]},{"location":"api/trackers/byte_track/","level":1,"title":"Module byte_track","text":"<p>trackforge / trackers / byte_track</p>","path":["Module byte_track"],"tags":[]},{"location":"api/trackers/byte_track/#module-byte_track","level":1,"title":"Module <code>byte_track</code>","text":"","path":["Module byte_track"],"tags":[]},{"location":"api/trackers/byte_track/#bytetrack","level":1,"title":"ByteTrack","text":"<p>ByteTrack: Multi-Object Tracking by Associating Every Detection Box</p> <p>Yifu Zhang, Peize Sun, Yi Jiang, Dongdong Yu, Fucheng Weng, Zehuan Yuan, Ping Luo, Wenyu Liu, Xinggang Wang</p> <p>arXiv 2110.06864</p> <p>ByteTrack is a simple, fast and strong multi-object tracker.</p>","path":["Module byte_track"],"tags":[]},{"location":"api/trackers/byte_track/#abstract","level":2,"title":"Abstract","text":"<p>Multi-object tracking (MOT) aims at estimating bounding boxes and identities of objects in videos. Most methods obtain identities by associating detection boxes whose scores are higher than a threshold. The objects with low detection scores, e.g. occluded objects, are simply thrown away, which brings non-negligible true object missing and fragmented trajectories. To solve this problem, ByteTrack presents a simple, effective and generic association method, tracking by associating every detection box instead of only the high score ones. For the low score detection boxes, it utilizes their similarities with tracklets to recover true objects and filter out the background detections.</p>","path":["Module byte_track"],"tags":[]},{"location":"api/trackers/byte_track/#original-repository","level":2,"title":"Original Repository","text":"<p>This is a clean-room Rust implementation of the ByteTrack algorithm as described in the original paper. The official reference implementation can be found at ifzhang/ByteTrack.</p>","path":["Module byte_track"],"tags":[]},{"location":"api/trackers/byte_track/#citation","level":2,"title":"Citation","text":"<pre><code>@article{zhang2022bytetrack,\n  title={ByteTrack: Multi-Object Tracking by Associating Every Detection Box},\n  author={Zhang, Yifu and Sun, Peize and Jiang, Yi and Yu, Dongdong and Weng, Fucheng and Yuan, Zehuan and Luo, Ping and Liu, Wenyu and Wang, Xinggang},\n  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},\n  year={2022}\n}\n</code></pre>","path":["Module byte_track"],"tags":[]},{"location":"api/trackers/byte_track/#quick-reference","level":2,"title":"Quick Reference","text":"Item Kind Description <code>ByteTrack</code> struct ByteTrack tracker implementation. <code>STrack</code> struct A Single Track (STrack) representing a tracked object. <code>TrackState</code> enum","path":["Module byte_track"],"tags":[]},{"location":"api/trackers/byte_track/#types","level":2,"title":"Types","text":"","path":["Module byte_track"],"tags":[]},{"location":"api/trackers/byte_track/#bytetrack_1","level":3,"title":"<code>ByteTrack</code>","text":"<pre><code>struct ByteTrack {\n    // [REDACTED: Private Fields]\n}\n</code></pre> <p>ByteTrack tracker implementation.</p> <p>ByteTrack is a simple, fast and strong multi-object tracker.</p>","path":["Module byte_track"],"tags":[]},{"location":"api/trackers/byte_track/#example","level":2,"title":"Example","text":"<pre><code>use trackforge::trackers::byte_track::ByteTrack;\n\n// Initialize tracker\nlet mut tracker = ByteTrack::new(0.5, 30, 0.8, 0.6);\n\n// Simulated detections: (tlwh_box, score, class_id)\nlet detections = vec![\n    ([100.0, 100.0, 50.0, 100.0], 0.9, 0),\n    ([200.0, 200.0, 60.0, 120.0], 0.85, 0),\n];\n\n// Update tracker\nlet tracks = tracker.update(detections);\n\nfor track in tracks {\n    println!(\"Track ID: {}, Box: {:?}\", track.track_id, track.tlwh);\n}\n</code></pre>","path":["Module byte_track"],"tags":[]},{"location":"api/trackers/byte_track/#abstract_1","level":2,"title":"Abstract","text":"","path":["Module byte_track"],"tags":[]},{"location":"api/trackers/byte_track/#implementations","level":4,"title":"Implementations","text":"<p> <pre><code>fn new(track_thresh: f32, track_buffer: usize, match_thresh: f32, det_thresh: f32) -&gt; Self\n</code></pre></p> <p>Create a new ByteTrack instance.</p> <p># Arguments</p> Argument Description <code>track_thresh</code> Threshold for high confidence detections (e.g., 0.5 or 0.6). <code>track_buffer</code> Number of frames to keep a lost track alive (e.g., 30). <code>match_thresh</code> IoU threshold for matching (e.g., 0.8). <code>det_thresh</code> Threshold for initializing a new track (usually same as or slightly lower than track_thresh). <p> <pre><code>fn update(&amp;mut self, output_results: Vec&lt;([f32; 4], f32, i64)&gt;) -&gt; Vec&lt;STrack&gt;\n</code></pre></p> <p>Update the tracker with detections from the current frame.</p> <p># Arguments</p> Argument Description <code>output_results</code> A vector of detections, where each detection is <code>(TLWH_Box, Score, ClassID)</code>. <p>Returns</p> <ul> <li><code>Vec&lt;STrack&gt;</code> - A list of active tracks in the current frame.</li> </ul>","path":["Module byte_track"],"tags":[]},{"location":"api/trackers/byte_track/#trait-implementations","level":4,"title":"Trait Implementations","text":"<p> <pre><code>fn to_subset(&amp;self) -&gt; Option&lt;SS&gt;\n</code></pre></p> <p> <pre><code>fn is_in_subset(&amp;self) -&gt; bool\n</code></pre></p> <p> <pre><code>fn to_subset_unchecked(&amp;self) -&gt; SS\n</code></pre></p> <p> <pre><code>fn from_subset(element: &amp;SS) -&gt; SP\n</code></pre></p>","path":["Module byte_track"],"tags":[]},{"location":"api/trackers/byte_track/#strack","level":3,"title":"<code>STrack</code>","text":"<pre><code>struct STrack {\n    pub tlwh: [f32; 4],\n    pub score: f32,\n    pub class_id: i64,\n    pub track_id: u64,\n    pub state: TrackState,\n    pub is_activated: bool,\n    pub frame_id: usize,\n    pub start_frame: usize,\n    pub tracklet_len: usize,\n    pub mean: crate::utils::kalman::StateVector,\n    pub covariance: crate::utils::kalman::CovarianceMatrix,\n}\n</code></pre> <p>A Single Track (STrack) representing a tracked object.</p>","path":["Module byte_track"],"tags":[]},{"location":"api/trackers/byte_track/#fields","level":4,"title":"Fields","text":"Name Type Description <code>tlwh</code> <code>[f32; 4]</code> Bounding box in TLWH (Top-Left-Width-Height) format. <code>score</code> <code>f32</code> Detection confidence score. <code>class_id</code> <code>i64</code> Class ID of the object. <code>track_id</code> <code>u64</code> Unique track ID. <code>state</code> <code>TrackState</code> Current tracking state (New, Tracked, Lost, Removed). <code>is_activated</code> <code>bool</code> Whether the track is currently activated (confirmed). <code>frame_id</code> <code>usize</code> Current frame ID. <code>start_frame</code> <code>usize</code> Frame ID where the track started. <code>tracklet_len</code> <code>usize</code> Length of the tracklet (number of frames tracked). <code>mean</code> <code>crate::utils::kalman::StateVector</code> Kalman Filter state mean. <code>covariance</code> <code>crate::utils::kalman::CovarianceMatrix</code> Kalman Filter state covariance.","path":["Module byte_track"],"tags":[]},{"location":"api/trackers/byte_track/#implementations_1","level":4,"title":"Implementations","text":"<p> <pre><code>fn new(tlwh: [f32; 4], score: f32, class_id: i64) -&gt; Self\n</code></pre></p> <p> <pre><code>fn activate(&amp;mut self, kf: &amp;KalmanFilter, frame_id: usize)\n</code></pre></p> <p> <pre><code>fn re_activate(&amp;mut self, new_track: STrack, frame_id: usize, new_id: bool)\n</code></pre></p> <p> <pre><code>fn update(&amp;mut self, new_track: STrack, frame_id: usize)\n</code></pre></p> <p> <pre><code>fn predict(&amp;mut self, kf: &amp;KalmanFilter)\n</code></pre></p>","path":["Module byte_track"],"tags":[]},{"location":"api/trackers/byte_track/#trait-implementations_1","level":4,"title":"Trait Implementations","text":"<pre><code>impl Clone for STrack\n</code></pre> <p> <pre><code>fn clone(&amp;self) -&gt; STrack\n</code></pre></p> <pre><code>impl Debug for STrack\n</code></pre> <p> <pre><code>fn fmt(&amp;self, f: &amp;mut fmt::Formatter&lt;'_&gt;) -&gt; fmt::Result\n</code></pre></p> <p> <pre><code>fn to_subset(&amp;self) -&gt; Option&lt;SS&gt;\n</code></pre></p> <p> <pre><code>fn is_in_subset(&amp;self) -&gt; bool\n</code></pre></p> <p> <pre><code>fn to_subset_unchecked(&amp;self) -&gt; SS\n</code></pre></p> <p> <pre><code>fn from_subset(element: &amp;SS) -&gt; SP\n</code></pre></p>","path":["Module byte_track"],"tags":[]},{"location":"api/trackers/byte_track/#trackstate","level":3,"title":"<code>TrackState</code>","text":"<pre><code>enum TrackState {\n    New,\n    Tracked,\n    Lost,\n    Removed,\n}\n</code></pre>","path":["Module byte_track"],"tags":[]},{"location":"api/trackers/byte_track/#trait-implementations_2","level":4,"title":"Trait Implementations","text":"<pre><code>impl Clone for TrackState\n</code></pre> <p> <pre><code>fn clone(&amp;self) -&gt; TrackState\n</code></pre></p> <pre><code>impl Copy for TrackState\n</code></pre> <pre><code>impl Debug for TrackState\n</code></pre> <p> <pre><code>fn fmt(&amp;self, f: &amp;mut fmt::Formatter&lt;'_&gt;) -&gt; fmt::Result\n</code></pre></p> <pre><code>impl Eq for TrackState\n</code></pre> <pre><code>impl PartialEq for TrackState\n</code></pre> <p> <pre><code>fn eq(&amp;self, other: &amp;TrackState) -&gt; bool\n</code></pre></p> <p> <pre><code>fn to_subset(&amp;self) -&gt; Option&lt;SS&gt;\n</code></pre></p> <p> <pre><code>fn is_in_subset(&amp;self) -&gt; bool\n</code></pre></p> <p> <pre><code>fn to_subset_unchecked(&amp;self) -&gt; SS\n</code></pre></p> <p> <pre><code>fn from_subset(element: &amp;SS) -&gt; SP\n</code></pre></p>","path":["Module byte_track"],"tags":[]},{"location":"api/trackers/deepsort/","level":1,"title":"Module deepsort","text":"<p>trackforge / trackers / deepsort</p>","path":["Module deepsort"],"tags":[]},{"location":"api/trackers/deepsort/#module-deepsort","level":1,"title":"Module <code>deepsort</code>","text":"","path":["Module deepsort"],"tags":[]},{"location":"api/trackers/deepsort/#quick-reference","level":2,"title":"Quick Reference","text":"Item Kind Description <code>DeepSort</code> struct","path":["Module deepsort"],"tags":[]},{"location":"api/trackers/deepsort/#types","level":2,"title":"Types","text":"","path":["Module deepsort"],"tags":[]},{"location":"api/trackers/deepsort/#deepsorte-appearanceextractor","level":3,"title":"<code>DeepSort&lt;E: AppearanceExtractor&gt;</code>","text":"<pre><code>struct DeepSort&lt;E: AppearanceExtractor&gt; {\n    // [REDACTED: Private Fields]\n}\n</code></pre>","path":["Module deepsort"],"tags":[]},{"location":"api/trackers/deepsort/#implementations","level":4,"title":"Implementations","text":"<p> <pre><code>fn new(extractor: E) -&gt; Self\n</code></pre></p>","path":["Module deepsort"],"tags":[]},{"location":"api/trackers/deepsort/#trait-implementations","level":4,"title":"Trait Implementations","text":"<p> <pre><code>fn to_subset(&amp;self) -&gt; Option&lt;SS&gt;\n</code></pre></p> <p> <pre><code>fn is_in_subset(&amp;self) -&gt; bool\n</code></pre></p> <p> <pre><code>fn to_subset_unchecked(&amp;self) -&gt; SS\n</code></pre></p> <p> <pre><code>fn from_subset(element: &amp;SS) -&gt; SP\n</code></pre></p>","path":["Module deepsort"],"tags":[]},{"location":"api/traits/","level":1,"title":"Module traits","text":"<p>trackforge / traits</p>","path":["Module traits"],"tags":[]},{"location":"api/traits/#module-traits","level":1,"title":"Module <code>traits</code>","text":"","path":["Module traits"],"tags":[]},{"location":"api/traits/#quick-reference","level":2,"title":"Quick Reference","text":"Item Kind Description <code>AppearanceExtractor</code> trait Trait for extracting appearance features (embeddings) from images.","path":["Module traits"],"tags":[]},{"location":"api/traits/#traits","level":2,"title":"Traits","text":"","path":["Module traits"],"tags":[]},{"location":"api/traits/#appearanceextractor","level":3,"title":"<code>AppearanceExtractor</code>","text":"<pre><code>trait AppearanceExtractor { ... }\n</code></pre> <p>Trait for extracting appearance features (embeddings) from images.</p> <p>This allows decoupling the tracker logic (DeepSORT) from the model execution (ONNX, PyTorch via Python, etc.).</p>","path":["Module traits"],"tags":[]},{"location":"api/traits/#required-methods","level":4,"title":"Required Methods","text":"<ul> <li><code>fn extract(&amp;self, image: &amp;DynamicImage, bboxes: &amp;[BoundingBox]) -&gt; Result&lt;Vec&lt;Vec&lt;f32&gt;&gt;, Box&lt;dyn Error&gt;&gt;</code></li> </ul> <p>Extract features for a list of bounding boxes from a given image.</p>","path":["Module traits"],"tags":[]},{"location":"api/types/","level":1,"title":"Module types","text":"<p>trackforge / types</p>","path":["Module types"],"tags":[]},{"location":"api/types/#module-types","level":1,"title":"Module <code>types</code>","text":"","path":["Module types"],"tags":[]},{"location":"api/types/#quick-reference","level":2,"title":"Quick Reference","text":"Item Kind Description <code>BoundingBox</code> struct Represents a bounding box in 2D space.","path":["Module types"],"tags":[]},{"location":"api/types/#types","level":2,"title":"Types","text":"","path":["Module types"],"tags":[]},{"location":"api/types/#boundingbox","level":3,"title":"<code>BoundingBox</code>","text":"<pre><code>struct BoundingBox {\n    pub x: f32,\n    pub y: f32,\n    pub width: f32,\n    pub height: f32,\n}\n</code></pre> <p>Represents a bounding box in 2D space.</p>","path":["Module types"],"tags":[]},{"location":"api/types/#implementations","level":4,"title":"Implementations","text":"<p> <pre><code>fn new(x: f32, y: f32, width: f32, height: f32) -&gt; Self\n</code></pre></p>","path":["Module types"],"tags":[]},{"location":"api/types/#trait-implementations","level":4,"title":"Trait Implementations","text":"<pre><code>impl Clone for BoundingBox\n</code></pre> <p> <pre><code>fn clone(&amp;self) -&gt; BoundingBox\n</code></pre></p> <pre><code>impl Copy for BoundingBox\n</code></pre> <pre><code>impl Debug for BoundingBox\n</code></pre> <p> <pre><code>fn fmt(&amp;self, f: &amp;mut fmt::Formatter&lt;'_&gt;) -&gt; fmt::Result\n</code></pre></p> <pre><code>impl PartialEq for BoundingBox\n</code></pre> <p> <pre><code>fn eq(&amp;self, other: &amp;BoundingBox) -&gt; bool\n</code></pre></p> <p> <pre><code>fn to_subset(&amp;self) -&gt; Option&lt;SS&gt;\n</code></pre></p> <p> <pre><code>fn is_in_subset(&amp;self) -&gt; bool\n</code></pre></p> <p> <pre><code>fn to_subset_unchecked(&amp;self) -&gt; SS\n</code></pre></p> <p> <pre><code>fn from_subset(element: &amp;SS) -&gt; SP\n</code></pre></p>","path":["Module types"],"tags":[]},{"location":"api/utils/","level":1,"title":"Module utils","text":"<p>trackforge / utils</p>","path":["Module utils"],"tags":[]},{"location":"api/utils/#module-utils","level":1,"title":"Module <code>utils</code>","text":"","path":["Module utils"],"tags":[]},{"location":"api/utils/#quick-reference","level":2,"title":"Quick Reference","text":"Item Kind Description <code>geometry</code> mod <code>kalman</code> mod","path":["Module utils"],"tags":[]},{"location":"api/utils/#modules","level":2,"title":"Modules","text":"<ul> <li><code>geometry</code></li> <li><code>kalman</code></li> </ul>","path":["Module utils"],"tags":[]},{"location":"api/utils/geometry/","level":1,"title":"Module geometry","text":"<p>trackforge / utils / geometry</p>","path":["Module geometry"],"tags":[]},{"location":"api/utils/geometry/#module-geometry","level":1,"title":"Module <code>geometry</code>","text":"","path":["Module geometry"],"tags":[]},{"location":"api/utils/geometry/#quick-reference","level":2,"title":"Quick Reference","text":"Item Kind Description <code>iou</code> fn <code>iou_batch</code> fn <code>tlwh_to_tlbr</code> fn","path":["Module geometry"],"tags":[]},{"location":"api/utils/geometry/#functions","level":2,"title":"Functions","text":"","path":["Module geometry"],"tags":[]},{"location":"api/utils/geometry/#iou","level":3,"title":"<code>iou</code>","text":"<pre><code>fn iou(box1: &amp;[f32; 4], box2: &amp;[f32; 4]) -&gt; f32\n</code></pre>","path":["Module geometry"],"tags":[]},{"location":"api/utils/geometry/#iou_batch","level":3,"title":"<code>iou_batch</code>","text":"<pre><code>fn iou_batch(bboxes1: &amp;[[f32; 4]], bboxes2: &amp;[[f32; 4]]) -&gt; Vec&lt;Vec&lt;f32&gt;&gt;\n</code></pre>","path":["Module geometry"],"tags":[]},{"location":"api/utils/geometry/#tlwh_to_tlbr","level":3,"title":"<code>tlwh_to_tlbr</code>","text":"<pre><code>fn tlwh_to_tlbr(tlwh: &amp;[f32; 4]) -&gt; [f32; 4]\n</code></pre>","path":["Module geometry"],"tags":[]},{"location":"api/utils/kalman/","level":1,"title":"Module kalman","text":"<p>trackforge / utils / kalman</p>","path":["Module kalman"],"tags":[]},{"location":"api/utils/kalman/#module-kalman","level":1,"title":"Module <code>kalman</code>","text":"","path":["Module kalman"],"tags":[]},{"location":"api/utils/kalman/#quick-reference","level":2,"title":"Quick Reference","text":"Item Kind Description <code>KalmanFilter</code> struct A standard Kalman Filter implementation for bounding box tracking. <code>CovarianceMatrix</code> type <code>MeasurementMatrix</code> type <code>MeasurementVector</code> type <code>StateVector</code> type","path":["Module kalman"],"tags":[]},{"location":"api/utils/kalman/#types","level":2,"title":"Types","text":"","path":["Module kalman"],"tags":[]},{"location":"api/utils/kalman/#kalmanfilter","level":3,"title":"<code>KalmanFilter</code>","text":"<pre><code>struct KalmanFilter {\n    // [REDACTED: Private Fields]\n}\n</code></pre> <p>A standard Kalman Filter implementation for bounding box tracking.</p> <p>Ref: \"Simple Online and Realtime Tracking with a Deep Association Metric\" (DeepSORT)</p>","path":["Module kalman"],"tags":[]},{"location":"api/utils/kalman/#implementations","level":4,"title":"Implementations","text":"<p> <pre><code>fn new(std_weight_position: f32, std_weight_velocity: f32) -&gt; Self\n</code></pre></p> <p>Create a new Kalman Filter instance.</p> <p> <pre><code>fn initiate(&amp;self, measurement: &amp;MeasurementVector) -&gt; (StateVector, CovarianceMatrix)\n</code></pre></p> <p>Initiate the Kalman Filter state from a measurement.</p> <p># Arguments</p> Argument Description <code>measurement</code> The initial measurement vector <code>[x, y, a, h]</code>. <p># Returns</p> <p>A tuple containing the initial Mean vector and Covariance matrix.</p> <p> <pre><code>fn predict(&amp;self, mean: &amp;StateVector, covariance: &amp;CovarianceMatrix) -&gt; (StateVector, CovarianceMatrix)\n</code></pre></p> <p> <pre><code>fn update(&amp;self, mean: &amp;StateVector, covariance: &amp;CovarianceMatrix, measurement: &amp;MeasurementVector) -&gt; (StateVector, CovarianceMatrix)\n</code></pre></p>","path":["Module kalman"],"tags":[]},{"location":"api/utils/kalman/#trait-implementations","level":4,"title":"Trait Implementations","text":"<pre><code>impl Clone for KalmanFilter\n</code></pre> <p> <pre><code>fn clone(&amp;self) -&gt; KalmanFilter\n</code></pre></p> <pre><code>impl Debug for KalmanFilter\n</code></pre> <p> <pre><code>fn fmt(&amp;self, f: &amp;mut fmt::Formatter&lt;'_&gt;) -&gt; fmt::Result\n</code></pre></p> <pre><code>impl Default for KalmanFilter\n</code></pre> <p> <pre><code>fn default() -&gt; Self\n</code></pre></p>","path":["Module kalman"],"tags":[]},{"location":"api/utils/kalman/#implr-readprimitiver-for-kalmanfilter","level":5,"title":"<code>impl&lt;R&gt; ReadPrimitive&lt;R&gt; for KalmanFilter</code>","text":"<p> <pre><code>fn to_subset(&amp;self) -&gt; Option&lt;SS&gt;\n</code></pre></p> <p> <pre><code>fn is_in_subset(&amp;self) -&gt; bool\n</code></pre></p> <p> <pre><code>fn to_subset_unchecked(&amp;self) -&gt; SS\n</code></pre></p> <p> <pre><code>fn from_subset(element: &amp;SS) -&gt; SP\n</code></pre></p>","path":["Module kalman"],"tags":[]},{"location":"api/utils/kalman/#covariancematrix","level":3,"title":"<code>CovarianceMatrix</code>","text":"<pre><code>type CovarianceMatrix = nalgebra::SMatrix&lt;f32, 8, 8&gt;;\n</code></pre>","path":["Module kalman"],"tags":[]},{"location":"api/utils/kalman/#measurementmatrix","level":3,"title":"<code>MeasurementMatrix</code>","text":"<pre><code>type MeasurementMatrix = nalgebra::SMatrix&lt;f32, 4, 8&gt;;\n</code></pre>","path":["Module kalman"],"tags":[]},{"location":"api/utils/kalman/#measurementvector","level":3,"title":"<code>MeasurementVector</code>","text":"<pre><code>type MeasurementVector = nalgebra::SVector&lt;f32, 4&gt;;\n</code></pre>","path":["Module kalman"],"tags":[]},{"location":"api/utils/kalman/#statevector","level":3,"title":"<code>StateVector</code>","text":"<pre><code>type StateVector = nalgebra::SVector&lt;f32, 8&gt;;\n</code></pre>","path":["Module kalman"],"tags":[]},{"location":"reference/python/","level":1,"title":"Python API Reference","text":"","path":["Python API Reference"],"tags":[]},{"location":"reference/python/#trackforge","level":2,"title":"<code>trackforge</code>","text":"","path":["Python API Reference"],"tags":[]},{"location":"reference/python/#trackforge.ByteTrack","level":3,"title":"<code>ByteTrack</code>","text":"<p>ByteTrack tracker implementation.</p> <p>Use <code>ByteTrack()</code> to initialize and <code>update()</code> to process frames.</p> <p>Usage Example:</p> <pre><code>from trackforge import ByteTrack\nimport numpy as np\n\n# Initialize tracker with default parameters\ntracker = ByteTrack(\n    track_thresh=0.5,\n    track_buffer=30,\n    match_thresh=0.8,\n    det_thresh=0.6\n)\n\n# Simulated detections: [x, y, w, h]\n# Format: (box, score, class_id)\ndetections = [\n    ([100.0, 100.0, 50.0, 100.0], 0.9, 0),\n    ([200.0, 200.0, 60.0, 120.0], 0.85, 0)\n]\n\n# Update tracker\ntracks = tracker.update(detections)\n\n# Process active tracks\nfor track in tracks:\n    track_id, box, score, class_id = track\n    print(f\"Track ID: {track_id}, Box: {box}\")\n</code></pre>","path":["Python API Reference"],"tags":[]},{"location":"reference/python/#trackforge.ByteTrack.__init__","level":4,"title":"<code>__init__(track_thresh=0.5, track_buffer=30, match_thresh=0.8, det_thresh=0.6)</code>","text":"<p>Initialize the ByteTrack tracker.</p> <p>Parameters:</p> Name Type Description Default <code>track_thresh</code> <code>float</code> <p>High confidence detection threshold. Defaults to 0.5.</p> <code>0.5</code> <code>track_buffer</code> <code>int</code> <p>Number of frames to keep lost tracks alive. Defaults to 30.</p> <code>30</code> <code>match_thresh</code> <code>float</code> <p>IoU matching threshold. Defaults to 0.8.</p> <code>0.8</code> <code>det_thresh</code> <code>float</code> <p>Initialization threshold. Defaults to 0.6.</p> <code>0.6</code>","path":["Python API Reference"],"tags":[]},{"location":"reference/python/#trackforge.ByteTrack.update","level":4,"title":"<code>update(output_results)</code>","text":"<p>Update the tracker with detections from the current frame.</p> <p>Parameters:</p> Name Type Description Default <code>output_results</code> <code>list</code> <p>A list of detections, where each detection is a tuple of ([x, y, w, h], score, class_id).</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>List[Tuple[int, List[float], float, int]]</code> <p>A list of active tracks, where each track is a tuple of (track_id, [x, y, w, h], score, class_id).</p>","path":["Python API Reference"],"tags":[]}]}